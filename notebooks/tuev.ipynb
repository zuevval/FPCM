{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05432f87",
   "metadata": {},
   "source": [
    "From TUEV Readme:\n",
    "\n",
    "lab files use 4 letter codes:\n",
    "\n",
    "- spsw: spike and slow wave  \n",
    "- gped: generalized periodic epileptiform discharge  \n",
    "- pled: periodic lateralized epileptiform discharge  \n",
    "- eyem: eye movement  \n",
    "- artf: artifact  \n",
    "- bckg: background\n",
    "\n",
    "In the format:\n",
    "`117100000 117200000 eyem`\n",
    "\n",
    "rec files use numeric codes:\n",
    "\n",
    "1: spsw  \n",
    "2: gped  \n",
    "3: pled  \n",
    "4: eyem  \n",
    "5: artf  \n",
    "6: bckg\n",
    "\n",
    "in the format: `13,90.4,91.4,6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24374fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhealth.datasets import TUEVDataset\n",
    "dataset = TUEVDataset(root=\"/share/Share/valera/tuev/edf/\")\n",
    "dataset.stat()\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc26af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Get all .edf file paths from dataset.patients\n",
    "edf_paths = []\n",
    "for records in dataset.patients.values():\n",
    "    for rec in records:\n",
    "        edf_paths.append(Path(rec[\"load_from_path\"]) / rec[\"signal_file\"])\n",
    "\n",
    "# Collect all events as tuples: (rec_path, label, chans_tuple, start, end)\n",
    "all_events = []\n",
    "\n",
    "for edf_path in edf_paths:\n",
    "    rec_path = edf_path.with_suffix(\".rec\")\n",
    "    if not rec_path.exists():\n",
    "        continue\n",
    "    try:\n",
    "        events = np.genfromtxt(rec_path, delimiter=\",\")\n",
    "        if events.ndim == 1 and events.size == 4:  # to 2D\n",
    "            events = events.reshape(1, 4)\n",
    "        # Group by (label, start, end): collect all channels for each event\n",
    "        event_dict = defaultdict(list)\n",
    "        for chan, start, end, label in events:\n",
    "            event_dict[(int(label), float(start), float(end))].append(int(chan))\n",
    "        # Store as (rec_path, label, chans_tuple, start, end)\n",
    "        for (label, start, end), chans in event_dict.items():\n",
    "            all_events.append((rec_path, label, tuple(sorted(set(chans))), start, end))\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {rec_path}: {e}\")\n",
    "\n",
    "# Sort events for merging\n",
    "all_events.sort(key=lambda x: (x[0], x[1], x[2], x[3], x[4]))\n",
    "\n",
    "# Merge successive intervals\n",
    "merged_events = []\n",
    "for event in all_events:\n",
    "    if not merged_events:\n",
    "        merged_events.append(event)\n",
    "        continue\n",
    "    last = merged_events[-1]\n",
    "    # If rec_path, label, chans are the same and last.end == event.start, merge\n",
    "    if (last[0] == event[0] and last[1] == event[1] and last[2] == event[2] and np.isclose(last[4], event[3])):\n",
    "        # Merge by updating the end time\n",
    "        merged_events[-1] = (last[0], last[1], last[2], last[3], event[4])\n",
    "    else:\n",
    "        merged_events.append(event)\n",
    "\n",
    "# Now, build event_channel_counts from merged_events\n",
    "event_channel_counts = defaultdict(list)\n",
    "for rec_path, label, chans, start, end in merged_events:\n",
    "    event_channel_counts[(rec_path, label, start, end)] = list(chans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b17b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# event_channel_counts: key = (rec_path, label, start, end), value = [chan, chan, ...]\n",
    "# We want: for each (label, n_channels), count how many events have that label and are in n_channels\n",
    "\n",
    "pair_counter = Counter()\n",
    "for key, chans in event_channel_counts.items():\n",
    "    _, label, _, _ = key\n",
    "    n_channels = len(set(chans))\n",
    "    pair_counter[(label, n_channels)] += 1\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(\n",
    "    [(label, n_channels, count) for (label, n_channels), count in pair_counter.items()],\n",
    "    columns=[\"label\", \"n_channels\", \"count\"]\n",
    ").sort_values([\"label\", \"n_channels\"]).reset_index(drop=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc211761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Mapping from label number to text\n",
    "label_map = {\n",
    "    1: \"spsw\",\n",
    "    2: \"gped\",\n",
    "    3: \"pled\",\n",
    "    4: \"eyem\",\n",
    "    5: \"artf\",\n",
    "    6: \"bckg\"\n",
    "}\n",
    "\n",
    "labels = df['label'].unique()\n",
    "label_counts = df.groupby('label')['count'].sum()\n",
    "\n",
    "# Outer: for each (label, n_channels)\n",
    "outer_sizes = df['count']\n",
    "outer_n_channels = df['n_channels'].values\n",
    "outer_labels = [f\"{row.n_channels}\" for row in df.itertuples()]\n",
    "\n",
    "# Inner: total for each label\n",
    "inner_sizes = label_counts.values\n",
    "inner_labels = [f\"{label_map.get(l, str(l))} ({label_counts[l]})\" for l in labels]\n",
    "\n",
    "# Colors\n",
    "cmap = plt.get_cmap(\"tab20c\")\n",
    "# Assign a color for each unique n_channels value\n",
    "unique_n_channels = sorted(df['n_channels'].unique())\n",
    "nchan_color_map = {n: cmap(i * 3 % 20) for i, n in enumerate(unique_n_channels)}\n",
    "outer_colors = [nchan_color_map[n] for n in outer_n_channels]\n",
    "inner_colors = cmap(np.arange(len(labels)) * 2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Inner pie (labels as text, closer to center)\n",
    "wedges1, _ = ax.pie(\n",
    "    inner_sizes, radius=1, labels=None,\n",
    "    colors=inner_colors, wedgeprops=dict(width=0.3, edgecolor='w')\n",
    ")\n",
    "\n",
    "# Place text labels closer to center, with total count in brackets\n",
    "for i, w in enumerate(wedges1):\n",
    "    ang = (w.theta2 + w.theta1) / 2\n",
    "    x = 0.5 * np.cos(np.deg2rad(ang))\n",
    "    y = 0.5 * np.sin(np.deg2rad(ang))\n",
    "    ax.text(x, y, inner_labels[i], ha='center', va='center', fontsize=14, weight='bold')\n",
    "\n",
    "# Outer pie (n_channels per label)\n",
    "outer_order = []\n",
    "for l in labels:\n",
    "    outer_order.extend(df[df['label'] == l].index.tolist())\n",
    "outer_sizes_ordered = df.loc[outer_order, 'count']\n",
    "outer_labels_ordered = [outer_labels[i] for i in outer_order]\n",
    "outer_colors_ordered = [outer_colors[i] for i in outer_order]\n",
    "\n",
    "# Remove labels for small sectors (e.g., <3% of total)\n",
    "total_outer = outer_sizes_ordered.sum()\n",
    "outer_labels_final = [\n",
    "    lbl if size / total_outer > 0.015 else \"\"  # 3% threshold\n",
    "    for lbl, size in zip(outer_labels_ordered, outer_sizes_ordered)\n",
    "]\n",
    "\n",
    "wedges2, _ = ax.pie(\n",
    "    outer_sizes_ordered, radius=1.3, labels=outer_labels_final, labeldistance=1.08,\n",
    "    colors=outer_colors_ordered, wedgeprops=dict(width=0.3, edgecolor='w')\n",
    ")\n",
    "\n",
    "ax.set(aspect=\"equal\")\n",
    "plt.subplots_adjust(top=0.85)  # Move the title higher\n",
    "plt.suptitle(\"Nested Pie Chart: Event Type (inner) and n_channels (outer)\", y=0.98, fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb02094",
   "metadata": {},
   "source": [
    "# per file stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b292f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# --- Gather statistics ---\n",
    "stats = []\n",
    "event_type_names = label_map\n",
    "\n",
    "for edf_path in edf_paths:\n",
    "    rec_path = edf_path.with_suffix(\".rec\")\n",
    "    if not rec_path.exists():\n",
    "        continue\n",
    "    try:\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=False, verbose=False)\n",
    "        n_channels = len(raw.ch_names)\n",
    "        length_sec = raw.n_times / raw.info[\"sfreq\"]\n",
    "        raw.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read {edf_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Count events by type\n",
    "    try:\n",
    "        events = np.genfromtxt(rec_path, delimiter=\",\")\n",
    "        if events.ndim == 1 and events.size == 4:\n",
    "            events = events.reshape(1, 4)\n",
    "        event_counts = Counter()\n",
    "        for row in events:\n",
    "            label = int(row[3])\n",
    "            event_counts[label] += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read {rec_path}: {e}\")\n",
    "        event_counts = Counter()\n",
    "\n",
    "    stats.append({\n",
    "        \"edf_path\": edf_path,\n",
    "        \"length_sec\": length_sec,\n",
    "        \"n_channels\": n_channels,\n",
    "        \"n_events_total\": sum(event_counts.values()),\n",
    "        \"event_counts\": dict(event_counts)\n",
    "    })\n",
    "\n",
    "# --- Plot distributions: length, n_channels, total events ---\n",
    "lengths = [s[\"length_sec\"] for s in stats]\n",
    "n_channels = [s[\"n_channels\"] for s in stats]\n",
    "n_events_total = [s[\"n_events_total\"] for s in stats]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=False)\n",
    "axes[0].hist(lengths, bins=50, color='C0')\n",
    "axes[0].set_title(\"Recording Length (seconds)\")\n",
    "axes[1].hist(n_channels, bins=np.arange(min(n_channels), max(n_channels)+2)-0.5, color='C1')\n",
    "axes[1].set_title(\"Number of Channels\")\n",
    "axes[2].hist(n_events_total, bins=50, color='C2')\n",
    "axes[2].set_title(\"Total Number of Events\")\n",
    "axes[2].set_xlabel(\"Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Plot distributions: number of events of each type ---\n",
    "event_types = sorted(event_type_names.keys())\n",
    "event_type_counts = {etype: [] for etype in event_types}\n",
    "for s in stats:\n",
    "    for etype in event_types:\n",
    "        event_type_counts[etype].append(s[\"event_counts\"].get(etype, 0))\n",
    "\n",
    "fig, axes = plt.subplots(6, 1, figsize=(10, 16), sharex=True)\n",
    "for i, etype in enumerate(event_types):\n",
    "    axes[i].hist(event_type_counts[etype], bins=50, color=f\"C{i}\")\n",
    "    axes[i].set_title(f\"Number of Events: {event_type_names[etype]} (label={etype}). Y axis: log scale\")\n",
    "    axes[i].set_yscale(\"log\")\n",
    "axes[-1].set_xlabel(\"Number of Events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ccc286",
   "metadata": {},
   "source": [
    "# SPSWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b35b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_channels = max(n_channels)\n",
    "\n",
    "print(\"Maximum number of channels:\", max_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f814cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "color_channels = False  # Set to False for grey axvspans\n",
    "\n",
    "# Find all SPSW events (label == 1)\n",
    "spsw_events = [k + (v,) for k, v in event_channel_counts.items() if k[1] == 1]\n",
    "n_spikes = len(spsw_events)\n",
    "spikes_per_plot = 8\n",
    "\n",
    "pdf_filename = f\"spsw_spikes_color_channels_{color_channels}.pdf\"\n",
    "with PdfPages(pdf_filename) as pdf:\n",
    "    for plot_idx in tqdm(range(0, n_spikes, spikes_per_plot)):\n",
    "        fig, axes = plt.subplots(max_channels, spikes_per_plot, figsize=(spikes_per_plot * 4, max_channels * 1.5), sharey='row', sharex=False)\n",
    "        if max_channels == 1:\n",
    "            axes = axes[np.newaxis, :]\n",
    "        for col, event_key in enumerate(spsw_events[plot_idx:plot_idx + spikes_per_plot]):\n",
    "            rec_path, label, start, end, chans = event_key\n",
    "            edf_path = rec_path.with_suffix('.edf')\n",
    "            try:\n",
    "                raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
    "                raw.pick(\"eeg\")\n",
    "                sfreq = raw.info[\"sfreq\"]\n",
    "                data, times = raw.get_data(return_times=True)\n",
    "                channel_names = raw.ch_names\n",
    "                raw.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load {edf_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Center of the event\n",
    "            center = (start + end) / 2\n",
    "            tmin = max(center - 1, 0)\n",
    "            tmax = center + 1\n",
    "            idx_min = np.searchsorted(times, tmin)\n",
    "            idx_max = np.searchsorted(times, tmax)\n",
    "\n",
    "            for ch_idx in range(len(channel_names)):\n",
    "                ax = axes[ch_idx, col] if max_channels > 1 else axes[col]\n",
    "                ax.plot(times[idx_min:idx_max], data[ch_idx, idx_min:idx_max], color='k', linewidth=0.7)\n",
    "                # Mark the SPSW interval\n",
    "                if color_channels:\n",
    "                    color = \"red\" if ch_idx in chans else \"green\"\n",
    "                else:\n",
    "                    color = \"grey\"\n",
    "                ax.axvspan(start, end, color=color, alpha=0.3)\n",
    "                if ch_idx == 0:\n",
    "                    ax.set_title(f\"{edf_path.name}\\nSPSW {plot_idx + col + 1}\", fontsize=10)\n",
    "                if col == 0:\n",
    "                    ax.set_ylabel(channel_names[ch_idx])\n",
    "                ax.set_xlim(tmin, tmax)\n",
    "                ax.grid(True)\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"Saved all SPSW plots to {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c531e604",
   "metadata": {},
   "source": [
    "# PLEDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5824ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "color_channels = True\n",
    "\n",
    "# Find all PLED events (label == 3) and select first 100\n",
    "pled_events = [k + (v,) for k, v in event_channel_counts.items() if k[1] == 3][:100]\n",
    "n_pled = len(pled_events)\n",
    "pled_per_plot = 3\n",
    "\n",
    "pdf_filename = f\"pled_spikes_color_channels_{color_channels}.pdf\"\n",
    "with PdfPages(pdf_filename) as pdf:\n",
    "    for plot_idx in tqdm(range(0, n_pled, pled_per_plot)):\n",
    "        # Use max_channels rows, pled_per_plot columns\n",
    "        fig, axes = plt.subplots(max_channels, pled_per_plot, figsize=(pled_per_plot * 4, max_channels * 1.5), sharey='row', sharex=False)\n",
    "        if max_channels == 1:\n",
    "            axes = axes[np.newaxis, :]\n",
    "        for col, event_key in enumerate(pled_events[plot_idx:plot_idx + pled_per_plot]):\n",
    "            rec_path, label, start, end, chans = event_key\n",
    "            edf_path = rec_path.with_suffix('.edf')\n",
    "            try:\n",
    "                raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
    "                raw.pick(\"eeg\")\n",
    "                sfreq = raw.info[\"sfreq\"]\n",
    "                data, times = raw.get_data(return_times=True)\n",
    "                channel_names = raw.ch_names\n",
    "                raw.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load {edf_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Center of the event\n",
    "            center = (start + end) / 2\n",
    "            tmin = max(center - 4, 0)\n",
    "            tmax = center + 4\n",
    "            idx_min = np.searchsorted(times, tmin)\n",
    "            idx_max = np.searchsorted(times, tmax)\n",
    "\n",
    "            for ch_idx in range(len(channel_names)):\n",
    "                ax = axes[ch_idx, col] if max_channels > 1 else axes[col]\n",
    "                ax.plot(times[idx_min:idx_max], data[ch_idx, idx_min:idx_max], color='k', linewidth=0.7)\n",
    "                # Mark the PLED interval\n",
    "                if color_channels:\n",
    "                    color = \"red\" if ch_idx in chans else \"green\"\n",
    "                else:\n",
    "                    color = \"grey\"\n",
    "                ax.axvspan(start, end, color=color, alpha=0.3)\n",
    "                if ch_idx == 0:\n",
    "                    ax.set_title(f\"{edf_path.name}\\nPLED {plot_idx + col + 1}\", fontsize=10)\n",
    "                if col == 0:\n",
    "                    ax.set_ylabel(channel_names[ch_idx])\n",
    "                ax.set_xlim(tmin, tmax)\n",
    "                ax.grid(True)\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "print(f\"Saved all PLED plots to {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61eb89",
   "metadata": {},
   "source": [
    "# run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "# Set the path to the .edf and .rec file\n",
    "record_path = Path(\"../data/aaaaaaar/aaaaaaar_00000001.edf\")\n",
    "rec_path = record_path.with_suffix(\".rec\")  # assumes aaaaaaar.rec is in the same folder\n",
    "\n",
    "# Load the signal\n",
    "raw = mne.io.read_raw_edf(record_path, preload=True)\n",
    "raw.pick(\"eeg\")  # only keep EEG channels\n",
    "sfreq = raw.info[\"sfreq\"]\n",
    "data, times = raw.get_data(return_times=True)\n",
    "\n",
    "# Save channel names before closing\n",
    "channel_names = raw.ch_names.copy()\n",
    "raw.close()\n",
    "\n",
    "# Load the .rec annotations\n",
    "events = np.genfromtxt(rec_path, delimiter=\",\")  # shape (N_events, 4)\n",
    "\n",
    "# Plot multiple EEG channels with annotations\n",
    "n_channels_to_plot = 21\n",
    "end_idx = 10000\n",
    "time_end = times[end_idx]\n",
    "\n",
    "fig, axes = plt.subplots(n_channels_to_plot, 1, figsize=(15, 2.5 * n_channels_to_plot), sharex=True)\n",
    "\n",
    "for i in range(n_channels_to_plot):\n",
    "    ax = axes[i]\n",
    "    ax.plot(times[:end_idx], data[i, :end_idx], label=channel_names[i], linewidth=0.5)\n",
    "    \n",
    "    # Add annotations for current channel\n",
    "    for chan, start, end, label in events:\n",
    "        if end >= time_end:\n",
    "            continue\n",
    "        if int(chan) == i:\n",
    "            ax.axvspan(start, end, color='red', alpha=0.3)\n",
    "            ax.text((start + end) / 2, np.max(data[i, :end_idx]) * 0.8,\n",
    "                    str(int(label)), color='black', ha='center', fontsize=8)\n",
    "    \n",
    "    ax.set_ylabel(\"Amp (V)\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.grid(True)\n",
    "\n",
    "axes[-1].set_xlabel(\"Time (s)\")\n",
    "# plt.suptitle(f\"EEG signals from {record_path.name} — First {n_channels_to_plot} channels\")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84301418",
   "metadata": {},
   "source": [
    "# Write EDF with annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d38ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from mne.annotations import Annotations\n",
    "from pathlib import Path\n",
    "\n",
    "# edf_paths = [Path(\"/Users/vzuev/Documents/git/gh_zuevval/FPCM/data/aaaaaaar/aaaaaaar_00000001.edf\")]\n",
    "\n",
    "# Mapping from label number to text\n",
    "label_map = {\n",
    "    1: \"spsw\",\n",
    "    2: \"gped\",\n",
    "    3: \"pled\",\n",
    "    4: \"eyem\",\n",
    "    5: \"artf\",\n",
    "    6: \"bckg\"\n",
    "}\n",
    "\n",
    "for edf_path in edf_paths:\n",
    "    rec_path = edf_path.with_suffix(\".rec\")\n",
    "    if not rec_path.exists():\n",
    "        continue\n",
    "    try:\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read {edf_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        events = np.genfromtxt(rec_path, delimiter=\",\")\n",
    "        if events.ndim == 1 and events.size == 4:\n",
    "            events = events.reshape(1, 4)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read {rec_path}: {e}\")\n",
    "        raw.close()\n",
    "        continue\n",
    "\n",
    "    # Prepare annotation lists\n",
    "    onsets, durations, descriptions = [], [], []\n",
    "    for chan, start, end, label in events:\n",
    "        onsets.append(start)\n",
    "        durations.append(end - start)\n",
    "        descriptions.append(label_map.get(int(label), str(int(label))))\n",
    "\n",
    "    # Add annotations to raw\n",
    "    annots = Annotations(onset=onsets, duration=durations, description=descriptions)\n",
    "    raw.set_annotations(annots)\n",
    "\n",
    "    # Write new EDF with annotations\n",
    "    out_path = edf_path.with_name(edf_path.stem + \"_annot.edf\")\n",
    "    try:\n",
    "        raw.export(out_path, fmt='edf', overwrite=True)\n",
    "        print(f\"Wrote: {out_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not write {out_path}: {e}\")\n",
    "    raw.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
