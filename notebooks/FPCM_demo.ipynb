{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56717904-2fc6-4e2f-b23e-1b710b7bb906",
   "metadata": {},
   "source": [
    "# FPCM & source localization: demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c82a66-9231-4771-96fe-3c1fc38f179c",
   "metadata": {},
   "source": [
    "May 2025\n",
    "\n",
    "Daria Kleeva \n",
    "\n",
    "dkleeva@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a37cb55-1e24-42e9-a9d1-df7fc41d0161",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1628f1a-6dd2-4286-9e96-95c7bca6f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from source_loc import fit_spike_dipoles, plot_modeled_topos, plot_dipoles_2d\n",
    "from utils import compute_performance\n",
    "from fpcm_detector import detect_spikes_fpcm\n",
    "from summary import make_epochs, plot_average_joint, plot_spike_topographies, overlay_spline_fit_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d5ab8-4e57-435c-814d-c2100e4f3726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "SUBJECT='Simulated patient'\n",
    "path = Path(\"/mnt/y/vzuev/datasets/eeg_etc/FPCMdata/sim_raw.fif\")\n",
    "path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c17d5-1d91-4ef1-99f9-d451c772ea12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_fif(path)\n",
    "raw.load_data()\n",
    "raw.filter(1,40)\n",
    "raw.pick('grad')\n",
    "raw.crop(0,100) #for quick demo\n",
    "true_peaks = [float(f\"{i}.2\") for i in range(0, 100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c69a33-937a-4371-9779-2aae6e6dfbcd",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7f6471-80ef-44d7-a33c-39267959c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = detect_spikes_fpcm(\n",
    "    raw,\n",
    "    peak_hw_ms = 30, # Half-width of the sharp spike (in milliseconds)\n",
    "    wave_hw_ms = 90, # Half-width of the slow wave following the spike (in milliseconds)\n",
    "    bkg_coeff   = 3, # Signal-to-noise ratio\n",
    "    err_peak_th = 0.3, # Maximum allowed relative fitting error for the spike segment\n",
    "    err_wave_th = 0.9, # Maximum allowed relative fitting error for the wave segment\n",
    "    hit_threshold = 3, # Minimum number of channels that must agree on a spike to accept it\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b808e6-d374-43ba-b866-547835db3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_performance(\n",
    "    true_latencies_s = true_peaks,  \n",
    "    results          = results,                \n",
    "    raw              = raw,                    \n",
    "    tolerance_ms     = 40,                     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d802349-fec7-4ef7-a71a-18c1796e6e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = make_epochs(raw, results, tmin=-0.5, tmax=0.5)\n",
    "plot_average_joint(epochs, title='Average spike')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cbc3eb-778e-42ad-82b0-819ecd97e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each subplot shows the spatial distribution of MEG signal at spike peak.   \n",
    "# Yellow dots indicate the \"hit\" channels that contributed to detection.\n",
    "\n",
    "# Show only first 30 spikes for the fast rendering\n",
    "num_show=30\n",
    "results_short=results.copy()\n",
    "for key in ['peaks_samples', 'events']:\n",
    "    results_short[key]=results_short[key][:num_show]\n",
    "\n",
    "plot_spike_topographies(raw, results_short, n_cols=7) #Replace results_short with results for the full set\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baece4f3-1d67-4c6d-83de-bf8296e82ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each subplot shows the raw data (black) and the fitted spline (red dashed) for one spike and one channel.\n",
    "overlay_spline_fit_grid(raw, results_short, n_cols=7, unit='uV',\n",
    "                                data_kw=dict(color='0.3'),\n",
    "                                spline_kw=dict(color='r', ls='--'))\n",
    "#Replace results_short with results for the full set\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b4dc1-5a96-4194-bfd4-99cf1c30f85e",
   "metadata": {},
   "source": [
    "## Dipole fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddeb12-9d78-48b4-9349-5d0e1a2f5109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the cortical source space, compute BEM model and build the forward model\n",
    "subjects_dir = path.parent / \"fsaverage\"\n",
    "subjects_dir.mkdir(exist_ok=True)\n",
    "mne.datasets.fetch_fsaverage(subjects_dir=subjects_dir)\n",
    "\n",
    "subject      = \"fsaverage\"\n",
    "src = mne.setup_source_space(\n",
    "    subject, spacing=\"ico4\",  \n",
    "    add_dist=False, subjects_dir=subjects_dir, verbose=False)\n",
    "model = mne.make_bem_model(subject=subject, subjects_dir=subjects_dir )\n",
    "bem = mne.make_bem_solution(model)\n",
    "trans = \"fsaverage\"\n",
    "fwd = mne.make_forward_solution(epochs.info, trans=trans, src=src, bem=bem, \n",
    "                                eeg=False, meg=epochs.get_channel_types(picks='data', unique=True)[0], n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c7524-81da-4057-9d2e-8dcf648b71bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply RAP-MUSIC algorithm to each spike using the forward model.  \n",
    "\n",
    "fit_res = fit_spike_dipoles(\n",
    "    epochs, # Spike-centered epochs (each epoch = one spike)\n",
    "    fwd, # Forward model (leadfield matrix)\n",
    "    t_window=(-0.1, 0.1),  # Time window (in seconds) around the spike apex used for source fitting\n",
    "    thr_music=0.8, # Threshold for subspace correlation (only dipoles with corr > thr_music are accepted)\n",
    "    thr_svd=0.95,  # Variance threshold for the signal subspace (used in SVD for RAP-MUSIC)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4155d65-916a-4a9d-a9e9-5e8ea8141eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All localized dipoles are projected onto the fsaverage cortical surface.  \n",
    "plot_dipoles_2d(\n",
    "        fit_res, \n",
    "        trans=subject,       \n",
    "        subject=subject,\n",
    "        subjects_dir=os.getenv(\"SUBJECTS_DIR\"),\n",
    "        color=\"crimson\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa340bb8-4b66-4426-8e3a-b87dc6307780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each spike, compare the measured topography at the spike peak  \n",
    "# with the synthetic topography generated from the fitted dipoles.  \n",
    "\n",
    "# Show first 30 for fast rendering\n",
    "show_num=30\n",
    "fit_res_short=fit_res.copy()\n",
    "for key in fit_res_short.keys():\n",
    "    fit_res_short[key]=fit_res_short[key][:show_num]\n",
    "\n",
    "plot_modeled_topos(epochs[:show_num], fit_res_short, fwd,\n",
    "                              n_cols=4, cmap=\"RdBu_r\", vmax=None)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FPCM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
